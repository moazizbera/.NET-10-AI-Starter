# .NET AI Starter

A practical, step-by-step journey into building **AI-powered applications using modern .NET**.

This repository focuses on **real-world AI integration** â€” not hype â€” showing how .NET developers can work with Generative AI **without Python and without cloud dependencies**.

---

## ğŸ“Œ Episodes Overview

- **Episode 1** â€“ Vision, Architecture, and AI Fundamentals  
- **Episode 2** â€“ Local AI Chat in Pure .NET (No Python) âœ…  
- **Episode 3** â€“ ASP.NET AI Web API (Local LLM) âœ…  
- **Episode 4** â€“ Conversation Memory & Prompt Engine  
- **Episode 5** â€“ Streaming AI APIs (SSE)  
- **Episode 6** â€“ RAG (Chat with Documents)  
- **Episode 7** â€“ UI Integration  

Each episode builds on the previous one and introduces complexity **only when it adds value**.

---

## ğŸš€ Episode 2 â€“ Local AI Chat in Pure .NET

### ğŸ¯ Goal

> Prove that .NET can consume and integrate Generative AI models just as effectively as Python.

This episode delivers a **local, streaming AI chat application built entirely in .NET**, using **Ollama** to run LLMs locally.

- No Python  
- No cloud APIs  
- No API keys  
- Zero cost  

---

## ğŸ§  Why a Console Application?

The console app is intentional:

- Removes ASP.NET and networking noise  
- Makes AI behavior visible  
- Keeps focus on AI integration fundamentals  
- Ideal for learning and experimentation  
- Provides a solid foundation for later API and UI layers  

---

## ğŸ›  Technology Stack (Episode 2)

- **.NET 9 / .NET 10 ready**  
- **C#**  
- **Ollama** (local LLM runtime)  
- **Phi-3** (example model)  
- HTTP-based chat protocol  
- Streaming responses (token-by-token)  

---

## ğŸ“‚ Repository Structure (High Level)

```text
.NET-10-AI-Starter/
â”‚
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ DotNet10Ai.Console/        â† Episode 2 (Console Chat)
â”‚   â””â”€â”€ DotNet10Ai.Api/            â† Episode 3 (Web API)
```

You can explore each project for more detailed structure.

---

## â–¶ï¸ Run the Console Chat (Episode 2)

From the repository root:

```bash
dotnet run --project src/DotNet10Ai.Console
```

You should see something like:

```text
DotNet AI Chat
Local â€¢ Ollama â€¢ Phi-3
Type /help for commands
```

---

## ğŸ’¬ Chat Commands (Console)

| Command  | Description               |
|----------|---------------------------|
| `/help`  | Show available commands   |
| `/clear` | Clear conversation        |
| `/exit`  | Exit the chat application |

---

## ğŸ¤– How AI Is Used in Episode 2

- Chat messages are sent to Ollama using HTTP (local endpoint)  
- Responses are streamed token-by-token  
- A **system prompt** defines the AI role (e.g., senior software architect)  
- Conversation history is preserved in memory (per run)  
- No model training is performed  

This mirrors how **production systems consume AI models**: they call models, they donâ€™t train them.

---

## ğŸ†š Do I Need Python for This?

**Short answer: No.**

- **Python** dominates model training and research.  
- **.NET** excels at AI integration, APIs, services, and production systems.  

Most real-world applications **use models rather than train them**.  
This project demonstrates that modern .NET is a **first-class option** for that role.

---

# ğŸ“¦ Episode 3 â€“ ASP.NET AI Web API (Local LLM)

Episode 3 exposes the local AI engine through a clean **ASP.NET Web API**, making it available to any client that can speak HTTP.

### ğŸ¯ Goal

Convert the local AI console engine into a reusable HTTP API that front-ends, tools, and services can call.

---

## ğŸŒ API Endpoint

**Route:**

```text
POST /api/chat
```

### ğŸ“¥ Request Example

```json
{
  "message": "Hello"
}
```

### ğŸ“¤ Response Example

```json
{
  "reply": "Hi! How can I assist you today?"
}
```

> The exact text will depend on your local model (e.g., Phi-3), but the shape of the response stays the same.

---

## ğŸ”Œ Technology (Episode 3)

- **ASP.NET Web API**  
- **Ollama** LLM runtime (local)  
- **Phi-3** (or another local model you configure)  
- JSON over HTTP  
- No cloud dependency  
- No Python requirement  

---

## â–¶ï¸ Run the Web API (Episode 3)

From the repository root:

```bash
dotnet run --project src/DotNet10Ai.Api
```

Then open Swagger UI in your browser:

```text
https://localhost:7085/swagger
```

From Swagger:

1. Open the `POST /api/chat` endpoint.  
2. Click **Try it out**.  
3. Use a body such as:  

   ```json
   {
     "message": "Explain .NET 10 in one paragraph."
   }
   ```

4. Click **Execute** and inspect the JSON reply.

---

## ğŸ¤ Episode 3 Outcome

After Episode 3, the project now supports:

- Local LLM inference exposed over HTTP  
- Integration with **any** front-end (web, mobile, desktop)  
- A clean separation between **AI engine** and **API layer**  
- A ready foundation for:  
  - Conversation memory (Episode 4)  
  - Streaming APIs (Episode 5)  
  - RAG and document chat (Episode 6)  
  - Rich UI (Episode 7)  

---

# ğŸ“¦ Episode 4 â€” Conversation Memory & Prompt Engine

## ğŸ¯ Objective
Enable **stateful multiâ€‘turn AI chat** that remembers previous user messages and context across requests â€” for both Console and Web API.

This upgrades the system from simple Q&A to **real conversation intelligence**.

---

## ğŸ§  Why Episode 4 Matters

Up to Episode 3, each chat request was isolated:

- user sends message  
- AI replies  
- conversation forgotten

Episode 4 enables:
- Memory retention  
- Multiâ€‘message reasoning  
- Coherent longâ€‘running conversations  
- AI that adapts to the user  

This is how every real AI assistant works.

---

## ğŸ” Highâ€‘Level Design

### ğŸŸ¢ Memory Type
- Inâ€‘memory only  
- Stored per session  
- Lost when process restarts  
- Trimmed when memory grows too large  

### ğŸŸ¢ Data Structure Example

```csharp
public class ConversationMemory
{
    public List<ChatMessage> Messages { get; }
}
```

### ğŸŸ¢ System Prompt Templates

Episode 4 introduces:
- a default system message
- stored as the first memory entry

> The prompt acts as the AIâ€™s personality and instruction layer.

---

## ğŸ”Œ API Change Summary

### Old format

```json
{ "prompt": "Hello" }
```

### New format

```json
{
  "messages": [
      {"role":"system", "content":"You are a .NET AI assistant."},
      {"role":"user", "content":"Hello"},
      {"role":"assistant", "content":"Hi there!"}
  ]
}
```

---

## âš™ï¸ Web API Behavior

- `/api/chat` now receives conversation memory
- history is appended for each call
- memory can be cleared

### New endpoint

`POST /api/chat/reset` â†’ clears memory

---

## ğŸ§° Episode Tasks

### 1ï¸âƒ£ Inâ€‘Memory Storage
Implement a shared list for message history.

### 2ï¸âƒ£ System Prompt Templates
Store a permanent system instruction.

### 3ï¸âƒ£ Stateful API Chat
Rewrite payload builder â†’ use messages[]

### 4ï¸âƒ£ Documentation
Add README + sample calls

---

## ğŸ§ª Completion Criteria

âœ” AI remembers previous messages  
âœ” Console behaves statefully  
âœ” Web API returns contextâ€‘aware replies  
âœ” Reset works  
âœ” Documentation updated  

---

## ğŸš« Out of Scope

These features are intentionally excluded:

- database persistence  
- OpenAI provider switching  
- multiâ€‘user identity  
- streaming output  
- embeddings or vector search  

They belong to future episodes.

---

## ğŸ“„ Summary

Episode 4 transforms the platform from stateless demo into **a real conversational AI engine**, paving the way for:

- Episode 5 streaming  
- Episode 6 RAG  
- Episode 7 UI chat

---

ğŸ§© Sub-tasks (linked issues)
- Task â€“ Add session-based conversation tracking (https://github.com/moazizbera/.NET-10-AI-Starter/issues/11)
- Task â€“ Implement conversation memory (in-memory first) https://github.com/moazizbera/.NET-10-AI-Starter/issues/12
- Task â€“ Add system prompt templates https://github.com/moazizbera/.NET-10-AI-Starter/issues/13
- Task â€“ Refactor /api/chat to support stateful conversations https://github.com/moazizbera/.NET-10-AI-Starter/issues/14
- Task â€“ Document memory & prompt strategy in README https://github.com/moazizbera/.NET-10-AI-Starter/issues/15
---
Episode 4 â€“ Conversation Memory
Status: Completed

---

## ğŸ“š Coming Soon
Episode 5 will add **streaming AI output using SSE**.

## ğŸ“š Coming Next

Planned upcoming episodes in this series:
- **Episode 6** â€“ RAG (Chat with Documents)  
- **Episode 7** â€“ UI Integration  

Each step builds on a solid, working foundation from the previous episodes.

---

## ğŸ“„ License

This project is licensed under the **MIT License**.
